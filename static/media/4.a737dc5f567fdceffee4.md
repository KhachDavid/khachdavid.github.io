# The Scallop Eye: A Marvel of Evolutionary Design
Check the simulation of the scallop eye [here](https://davidk.tech/scallops).
</br>
</br>

<img src="https://raw.githubusercontent.com/KhachDavid/static/refs/heads/main/scallops/sclp.gif" height="60%" width="60%">
<p style="
    font-size: 0.8em;
    font-style: italic;
    color: #777;
">
</p>
</br>

Scallops possess a unique and fascinating visual system, one of the most intricate in the animal kingdom. Depending on the species, a scallop can have up to 200 eyes, which are distributed along the margins of their shell (valve), providing a panoramic view spanning approximately 270 degrees. They also interact with the outside world using their tentacles to receive tactile and chemical feedback.

### Photonic Nanospheres and Blue Light

<img src="https://raw.githubusercontent.com/KhachDavid/static/refs/heads/main/scallops/bay_vs_sea_scallop.png" height="50%" width="50%">
<p style="
    font-size: 0.8em;
    font-style: italic;
    color: #777;
">
Image (a) by David Liittschwager and Image (b) by Sönke Johnsen
</p>
</br>

One fascinating feature of scallop eyes is the presence of photonic nanospheres within the epithelial cells that cover the eye [1]. These photonic nanospheres help enhance the eye's ability to capture and reflect light. This is especially advantageous for species like the Bay Scallop (Argopecten irradians), which live in shallow waters where blue light predominates. In contrast, Sea Scallops, which reside deeper in the ocean, do not have the same blue-reflecting guanine lens, as their environment doesn't require it.

### The Eyes: Structure and Function

<img src="https://raw.githubusercontent.com/KhachDavid/static/refs/heads/main/scallops/eye_diagram.png" height="50%" width="50%">
<p style="
    font-size: 0.8em;
    font-style: italic;
    color: #777;
">
Palmer 2017. The image-forming mirror in the eye of the scallop.
</p>
</br>

This fluorescence microscopy image showcases the remarkable anatomy of a scallop's eye, with cell nuclei stained with DAPI for clarity [2]. The cross-section reveals the distinct structures that contribute to its unique optical system:
</br>
</br>

**The Cornea (i):**
At the outermost layer of the eye, the cornea is relatively unremarkable compared to the other structures. It acts as a protective barrier and allows light to enter the eye but does not play a significant role in focusing light.

</br>
</br>

**The Lens (ii):**
Positioned behind the cornea, the lens in a scallop eye is quite different from that of vertebrates. It is weakly refractive, more akin to a UV-blocking sunglass than the highly focusing lenses of human eyes. Instead of sharply bending light to focus it onto a single retina, it allows light to pass through in a broad manner, accommodating the unique optical design of the scallop eye.

</br>
</br>

**The Distal Retina (iii):**
Located closer to the light source, the distal retina is used for detecting fine details and high-acuity vision. It contains photoreceptors that are sensitive to specific wavelengths of light, allowing the scallop to perceive its environment with precision. The distal retina is also involved in color vision, helping the scallop distinguish between different objects and stimuli.

</br>
</br>

**The Proximal Retina (iv):**
Deeper within the eye, the proximal retina is specialized to detect peripheral motion and changes in light intensity. It is more sensitive to low-frequency stimuli, making it ideal for detecting movement across a wide field of view. The proximal retina complements the distal retina, providing the scallop with a comprehensive visual system that can detect both broad movements and fine details.

</br>
</br>

**The Mirror (v):**
At the back of the scallop's eye, the mirror is the defining feature of this optical system. Its structure is fascinating, comprising tessellated, segmented plates that resemble the design of high-precision telescopes. These plates are perfectly arranged to reflect light back onto the retinas. The red box in the image marks the center of the mirror, which reflects incoming light with high efficiency.

<img src="https://raw.githubusercontent.com/KhachDavid/static/refs/heads/main/scallops/crystal_layer.png" height="50%" width="50%">
<p style="
    font-size: 0.8em;
    font-style: italic;
    color: #777;
    padding-bottom: 10px;
">
Top view of a single crystal layer in the mirror of the scallop eye. Image by Palmer et al. (2017).

What makes this mirror truly special is its ability to selectively reflect blue-green light—wavelengths prevalent in the scallop's underwater habitat. This reflection not only aligns perfectly with the absorption maxima of the photoreceptors in both retinas but also optimizes the scallop's vision for its environment.

</br>

<img src="https://raw.githubusercontent.com/KhachDavid/static/refs/heads/main/scallops/segmented_mirrors.png" height="50%" width="50%">
<p style="
    font-size: 0.8em;
    font-style: italic;
    color: #777;
">
Source: Wikipedia.
</p>
</br>

On closer inspection, the tessellations of the mirror reveal a complex, highly ordered design. This segmented structure maximizes reflection and mimics the arrangement seen in advanced telescopic mirrors, a convergence of biological and engineering marvels.

### Reflectivity and Light Spectrum

<img src="https://raw.githubusercontent.com/KhachDavid/static/refs/heads/main/scallops/reflectivity_spectrum.png" height="50%" width="50%">
<p style="
    font-size: 0.8em;
    font-style: italic;
    color: #777;
">
Palmer 2017. The image-forming mirror in the eye of the scallop.
</p>
</br>

To measure the reflectivity of the mirror in the scallop's eye, Palmer (2017) conducted an experiment where simulated reflectivity spectra were overlaid with an irradiance spectrum. They measured that the reflectivity of the scallop's eye mirror peaks around 500 nm, where blue-green light is abundant. This wavelength range coincides with the absorption maxima of the photoreceptors in the retina, further enhancing the scallop's ability to perceive light within its environment. They have found that the morphology of the crystals in the mirror is not random; it is highly controlled to maximize reflectivity while minimizing defects.

### Side Note: Is Kepler wrong?

<img src="https://raw.githubusercontent.com/KhachDavid/static/refs/heads/main/scallops/einstein_tile.png" height="50%" width="50%">
<p style="
    font-size: 0.8em;
    font-style: italic;
    color: #777;
">
Smith 2023. An aperiodic monotile.
</p>
</br>


When explaining the tiling of the mirror, Palmer (2017) cited Kepler's 1619 paper on tessellation. Kepler showed that hexagons, triangles, and squares are the only shapes that can completely tile a surface. Well, as of last year, this is not true. An amateur mathematician, David Smith, discovered a new shape that can tile a surface [3]. This shape is called the "Hat." It kind of looks like an untucked shirt. Unfortunately, this shape is not found in the scallop's eye, but how cool would that be? 

### Visual Sensitivity: The Retina’s Role

<img src="https://raw.githubusercontent.com/KhachDavid/static/refs/heads/main/scallops/zero_frequency_intensity.png" height="50%" width="50%">
<p style="
    font-size: 0.8em;
    font-style: italic;
    color: #777;
">
Palmer 2017. The image-forming mirror in the eye of the scallop.
</p>
</br>

The scallop’s eye has two retinas: the proximal and distal retinas. The proximal retina is more sensitive to light, making it ideal for detecting movement across a wide field. In contrast, the distal retina is specialized for high-acuity vision, allowing the scallop to focus on finer details.

### Checkerboard Stimuli and Retinal Response

<img src="https://raw.githubusercontent.com/KhachDavid/static/refs/heads/main/scallops/checkerboard.png" height="50%" width="50%">
<p style="
    font-size: 0.8em;
    font-style: italic;
    color: #777;
">
Palmer 2017. The image-forming mirror in the eye of the scallop.
</p>
</br>


Interestingly, the sensitivity of the retina varies across these two regions. The proximal retina exhibits higher sensitivity to low-frequency stimuli (broad movements), while the distal retina is more sensitive to high-frequency stimuli (fine details). This division of labor mirrors the way mammalian visual systems function, where the cone cells detect rapid changes, and the rod cells are specialized for low-light, wide-field vision.

I encourage you to confirm this visually. Make sure you see how within the inner purple circle, distal retina has less blue than the proximal retina. Therefore, the red dot is the best image formed on the distal retina and the yellow dot is the best image formed on the proximal retina. Cyan dot is just the center of the vision. The modulation transfer function below enumerates the contrast loss as the details get finer.

### Modulation Transfer Function

<img src="https://raw.githubusercontent.com/KhachDavid/static/refs/heads/main/scallops/modulation_transfer_function.png" height="50%" width="50%">
<p style="
    font-size: 0.8em;
    font-style: italic;
    color: #777;
">
Palmer 2017. The image-forming mirror in the eye of the scallop.
</p>
</br>

MTFs describe the contrast reduction as spatial frequency increases. Zero angular frequency here is just the absolute zero-frequency intensity that we looked at previously. Here we have the graph of the red dot, yellow dot, and the cyan dot. Yellow dot is in the peripheral region where the best image on the proximal retina is formed. You can see for the cyan dot the decline is much sharper in the proximal retina than in the distal. This is even more apparent for the red dot. In contrast, the proximal retina has a much higher 50% cut off frequency than the distal retina.

### Behavioral Implications and Tentacle Use
<img src="https://raw.githubusercontent.com/KhachDavid/static/refs/heads/main/scallops/scallop_tentacles.png" height="50%" width="50%">
<p style="
    font-size: 0.8em;
    font-style: italic;
    color: #777;
">
Chappell 2021. Panoramic spatial vision in the bay scallop Argopecten irradians
</p>
</br>

Scallops are known for their ability to swim, a behavior that is closely tied to their vision system. When exposed to visual stimuli, such as striped images, scallops exhibit movement in their tentacles, indicating that they use vision to process and react to environmental changes [4]. The tentacles act as an extension of the visual system, providing the scallop with more information about its surroundings, especially for tasks like detecting movement or tracking objects. The tentacles are equipped with chemical information sensors and can detect between predators, such as sea stars, and non-predators, such as sea urchins.
</br>
</br>
<img src="https://raw.githubusercontent.com/KhachDavid/static/refs/heads/main/scallops/tentacle_extension_distribution.png" height="50%" width="50%">
<p style="
    font-size: 0.8em;
    font-style: italic;
    color: #777;
">
Chappell 2021. <b>c, d, e</b> show strong support of circular distribution
</p>
</br>

In the paper, <i>Panaromic spatial vision in the bay scallop</i>, Chappell showed that there is a strong statistical significance in the mean angle of the tentacle extensions when exposed to stimuli in <i>anterior, ventral, and posterior</i>. This shows that scallops have $270°$ spatial vision.


### Intraocular Vision and Acuity

The scallop's intraocular vision, or the comparison between the photoreceptors in each eye, allows it to create a panoramic view of its surroundings. The entire system works together to identify potential threats, locate prey, or detect environmental changes. This is what the simulator is depicting. The eyes, however, are not the sole players in this process—scallops also rely on their tentacles for tactile and chemical feedback, integrating multiple forms of sensory input.

### Making Distributed Visual Systems: Traditional Machine Learning

<img src="https://raw.githubusercontent.com/KhachDavid/static/refs/heads/main/scallops/bg_subtraction.png" height="50%" width="50%">
<p style="
    font-size: 0.8em;
    font-style: italic;
    color: #777;
">
Yuan 2003. A distributed visual surveillance system. Detecting intruders in a scene. In this case cars and people.
</p>
</br>


Interestingly, the scallop's visual processing shares similarities with traditional machine learning approaches of object detection. For example, scallops may generate a hypothesis about the presence of a moving object based on visual input (background subtraction), which is similar to how computer vision systems identify changes in a scene in a 2003 paper by Yuan called <i>A distributed visual surveillance system</i> [5]. 

Gabor filters are used to extract features from the image, which are then used to classify objects. The Gabor filter is a linear filter used for texture analysis, edge detection, and feature extraction. It is based on the Gabor function, which is defined as:
<div style="text-align: center; padding-top: 1rem; padding-bottom: 1rem; font-size: 20px;">

$g(x, y) = \frac{1}{2\pi\sigma^2}e^{-\frac{x^2 + y^2}{2\sigma^2}}e^{i2\pi jWx}$
</div>

Where $x$ and $y$ are the spatial coordinates, $\sigma$ is the standard deviation of the Gaussian function, $j$ is the imaginary unit, and $W$ is the frequency of the sinusoidal function. Gabor filters are essentially Gaussian filters modulated by a sinusoidal plane wave [6].

The scallop's brain then uses the features extracted from their tentacles to verify this hypothesis, akin to how a system might use feature classification, such as a Support Vector machine in Yuan's paper. With the recent advancements in deep learning, these traditional machine learning approaches are being replaced by more sophisticated neural networks that can learn complex patterns and features directly from the data. There is still a niche for traditional ML methods in scenarios with sparse data, but deep learning methods are offering a much higher accuracy. In the next section, we will explore how deep learning can be applied to scallop-like visual systems.

### Deep Learning based approaches

<img src="https://raw.githubusercontent.com/KhachDavid/static/refs/heads/main/scallops/fusion_algorithm.png" height="50%" width="50%">
<p style="
    font-size: 0.8em;
    font-style: italic;
    color: #777;
">
Yousefi et al 2023. Tracking of moving human in different overlapping cameras using Kalman filter optimized
</p>
</br>

Deep learning has revolutionized the field of computer vision, enabling the development of sophisticated algorithms that can detect, track, and classify objects in real-time. For example, Yousefi et al. (2023) developed a system that can track moving humans across different overlapping cameras using a Kalman filter optimized with deep learning techniques [7]. This system leverages the power of neural networks to process large amounts of visual data and make accurate predictions about object movement and behavior.

An important answer that Yousefi answers is why not have all the cameras run their own object detection algorithm and then fuse the results? The answer is that the fusion algorithm is more efficient and accurate. The fusion algorithm can take into account the spatial and temporal relationships between the cameras, improving the overall tracking performance. This is similar to how the scallop's visual system integrates information from multiple eyes to create a comprehensive view of its environment.

The above diagram describes the algorithm proposed by Yousefi et al for tracking moving humans across different overlapping cameras. The first step is background subtraction, where the system identifies moving objects in the scene. Next, the system uses a Fuzzy-PI controller to predict the position of the object in the next frame. Finally, a Kalman filter optimized is used to extract the object's trajectory. Then a genetic algorithm is used to optimize the feature extraction process. This multi-step approach combines the power of deep learning with traditional machine learning techniques to create a robust and accurate tracking system. 

Below is an image showing the multi camera system detecting people in the same scene:

<img src="https://raw.githubusercontent.com/KhachDavid/static/refs/heads/main/scallops/multi_camera_fov.png" height="50%" width="50%">
<p style="
    font-size: 0.8em;
    font-style: italic;
    color: #777;
">
Yousefi et al 2023. Tracking of moving human in different overlapping cameras using Kalman filter optimized

The F1 score is a measure of a test's accuracy. It considers both the precision and the recall of the test to compute the score. The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst at 0. The F1 score is calculated using the following formula:

<div style="text-align: center; padding-top: 1rem; padding-bottom: 1rem; font-size: 20px;">

$F1 = 2 * \frac{precision * recall}{precision + recall}$
</div>

This proposed algorithm achieved an F1 score of 0.9706 in hazy daytime vision, indicating high accuracy in tracking moving humans across different overlapping cameras. The system's ability to integrate information from multiple sources and optimize the tracking process demonstrates the power of multi-camera systems in object detection.

While the scallop's visual system is far more complex than the algorithms used in computer vision, the principles of integrating multiple sources of information to create a comprehensive view of the environment are shared between the two systems. By studying the scallop's eye and its unique optical design, we can gain insights into how to optimize computer vision systems for real-world applications.
</br>
</br>
<img src="https://raw.githubusercontent.com/KhachDavid/static/refs/heads/main/scallops/F_score_hazy.png" height="50%" width="50%">
<p style="
    font-size: 0.8em;
    font-style: italic;
    color: #777;
">
Yousefi et al 2023. Tracking of moving human in different overlapping cameras using Kalman filter optimized

</p>
</br>


### Conclusion

The scallop eye is a marvel of evolutionary adaptation, optimized for underwater vision and offering fascinating insights into the intersection of biology, physics, and engineering. Its unique combination of complex mirror design, guanine crystal structure, and multi-functional sensory input systems make it a prime example of nature’s ingenuity. Understanding these natural systems not only illuminates the scallop’s world but also offers inspiration for advancements in technology, from optical systems to surveillance and beyond.

#### References
<small>

[1] Harris OK, Kingston ACN, Wolfe CS, Ghoshroy S, Johnsen S, Speiser DI. Core-shell nanospheres behind the blue eyes of the bay scallop Argopecten irradians. J R Soc Interface. 2019 Oct 31;16(159):20190383. doi: 10.1098/rsif.2019.0383. Epub 2019 Oct 23. PMID: 31640501; PMCID: PMC6833330.

[2] Palmer, B. A., Taylor, G. J., Brumfeld, V., Gur, D., Shemesh, M., Elad, N., Osherov, A., Oron, D., Weiner, S., & Addadi, L. (2017). The image-forming mirror in the eye of the scallop. Science, 358(6367), 1172–1175. https://doi.org/10.1126/science.aam9506

[3] D. Smith, J. S. Myers, C. S. Kaplan, and C. Goodman-Strauss, "An aperiodic monotile," arXiv:2303.10798 [math.CO], Mar. 2023. [Online]. Available: https://doi.org/10.48550/arXiv.2303.10798

[4] Chappell, D. R., Horan, T. M., & Speiser, D. I. (2021). Panoramic spatial vision in the bay scallop Argopecten irradians. Proceedings of the Royal Society B: Biological Sciences, 288(1961), 20211730. https://doi.org/10.1098/rspb.2021.1730Chappell, D. R., Horan, T. M., & Speiser, D. I. (2021). Panoramic spatial vision in the bay scallop Argopecten irradians. Proceedings of the Royal Society B: Biological Sciences, 288(1961), 20211730. https://doi.org/10.1098/rspb.2021.1730 

[5] Yuan, Xiaojing & Sun, Zehang & Varol, Y.L. & Bebis, G.. (2003). A distributed visual surveillance system. 199- 204. 10.1109/AVSS.2003.1217922.

[6] J. G. Daugman, "Complete discrete 2-D Gabor transforms by neural networks for image analysis and compression," in IEEE Transactions on Acoustics, Speech, and Signal Processing, vol. 36, no. 7, pp. 1169-1179, July 1988, doi: 10.1109/29.1644. keywords: {Discrete transforms;Neural networks;Image segmentation;Image coding;Two dimensional displays;Image analysis}, 

[7] Yousefi, S.M.M., Mohseni, S.S., Dehbovid, H. et al. Tracking of moving human in different overlapping cameras using Kalman filter optimized. EURASIP J. Adv. Signal Process. 2023, 114 (2023). https://doi.org/10.1186/s13634-023-01078-z

</small>